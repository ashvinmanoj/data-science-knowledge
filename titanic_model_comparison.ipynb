{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Model Comparison\n",
    "\n",
    "### Sources\n",
    "\n",
    "- https://www.kaggle.com/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
    "- http://aplunket.com/titanic-comparing-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T03:59:47.447399Z",
     "start_time": "2018-06-28T03:59:46.405775Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jun 28 2018 \n",
      "\n",
      "CPython 3.6.5\n",
      "IPython 6.4.0\n",
      "\n",
      "numpy 1.14.5\n",
      "scipy 1.1.0\n",
      "sklearn 0.19.1\n",
      "pandas 0.23.1\n",
      "xgboost 0.72\n",
      "\n",
      "compiler   : GCC 4.2.1 Compatible Apple LLVM 9.1.0 (clang-902.0.39.1)\n",
      "system     : Darwin\n",
      "release    : 17.6.0\n",
      "machine    : x86_64\n",
      "processor  : i386\n",
      "CPU cores  : 8\n",
      "interpreter: 64bit\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext watermark\n",
    "%watermark -v -n -m -p numpy,scipy,sklearn,pandas,xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T03:59:47.453452Z",
     "start_time": "2018-06-28T03:59:47.450027Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data manipulation tools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T03:59:59.654517Z",
     "start_time": "2018-06-28T03:59:59.627139Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/Users/patornute/.kaggle/competitions/titanic/train.csv')\n",
    "df_test = pd.read_csv('/Users/patornute/.kaggle/competitions/titanic/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:00:07.317582Z",
     "start_time": "2018-06-28T04:00:07.260407Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patornute/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/pandas/core/frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "df_total = df_train.append(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:00:08.356729Z",
     "start_time": "2018-06-28T04:00:08.344716Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T09:14:01.474827Z",
     "start_time": "2018-06-26T09:14:01.467010Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleansing & Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:04:10.995072Z",
     "start_time": "2018-06-28T04:04:10.952532Z"
    }
   },
   "outputs": [],
   "source": [
    "#The survived column doesn't exist in the test set so find the train data from looking for NaN values\n",
    "df_total['Train'] = df_total['Survived'].apply(lambda x:0 if np.isnan(x) else 1) \n",
    "\n",
    "#Update NaN values\n",
    "df_total['Age'] = df_total['Age'].fillna(df_total['Age'].mean())\n",
    "df_total['Fare'] = df_total['Fare'].fillna(df_total['Fare'].mean())\n",
    "df_total['Embarked'] = df_total['Embarked'].fillna(df_total['Embarked'].mode()[0])\n",
    "\n",
    "#Create Title variable from the Name field\n",
    "df_total['Title'] = df_total['Name'].str.split(\".\").str[0]\n",
    "df_total['Title'] = df_total['Title'].str.split(\" \").str[-1]\n",
    "\n",
    "df_total.drop('Name', axis=1, inplace=True)\n",
    "\n",
    "def updateTitle(s):\n",
    "    if s in ['Mlle', 'Ms', 'Mme']:\n",
    "        return 'Miss'\n",
    "    elif s in ['Mr', 'Miss', 'Mrs', 'Master']:\n",
    "        return s\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "df_total['Title'] = df_total['Title'].apply(lambda x: updateTitle(x))\n",
    "\n",
    "#Create FamilySize variable\n",
    "df_total['FamilySize'] = df_total['SibSp'] + df_total['Parch'] \n",
    "df_total.drop('SibSp', axis=1, inplace=True)\n",
    "df_total.drop('Parch', axis=1, inplace=True)\n",
    "df_total['FamilySize'] = df_total['FamilySize'].apply(lambda x: 4 if x > 4 else x)\n",
    "\n",
    "#Get the first character of the Ticket variable\n",
    "df_total['Ticket'] = df_total['Ticket'].str[0:1]\n",
    "\n",
    "#Get the first character of the Cabin variable and replace NaN with Unknown\n",
    "df_total['Cabin'] = df_total['Cabin'].str[0]\n",
    "df_total['Cabin'] = df_total['Cabin'].fillna(df_total['Cabin'].mode()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scale Age, Fare and Family Size Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:06:08.580202Z",
     "start_time": "2018-06-28T04:06:08.551786Z"
    }
   },
   "outputs": [],
   "source": [
    "#Scale Age, Fare and Family Size Variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "scale_columns = ['Age', 'Fare', 'FamilySize']\n",
    "df_total_s = sc.fit_transform(df_total[scale_columns])\n",
    "df_total_s = pd.DataFrame((df_total_s), columns=scale_columns, index=df_total.index.get_values())\n",
    "\n",
    "#add the scaled columns back into the dataframe\n",
    "df_total[scale_columns] = df_total_s\n",
    "\n",
    "#One-Hot Encode Data\n",
    "df_total = pd.get_dummies(df_total, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create X_train, y_train and X_test variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:08:11.039374Z",
     "start_time": "2018-06-28T04:08:11.030681Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = df_total[df_total['Train'] == 1].drop(['Survived', 'PassengerId', 'Train'], axis=1)\n",
    "y_train = df_total[df_total['Train'] == 1]['Survived']\n",
    "\n",
    "X_test = df_total[df_total['Train'] == 0].drop(['Survived', 'PassengerId', 'Train'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:09:32.817566Z",
     "start_time": "2018-06-28T04:09:32.796333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>...</th>\n",
       "      <th>Ticket_C</th>\n",
       "      <th>Ticket_F</th>\n",
       "      <th>Ticket_L</th>\n",
       "      <th>Ticket_P</th>\n",
       "      <th>Ticket_S</th>\n",
       "      <th>Ticket_W</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.358655</td>\n",
       "      <td>-0.492396</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.659690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.329283</td>\n",
       "      <td>-0.508429</td>\n",
       "      <td>3</td>\n",
       "      <td>0.195294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.494035</td>\n",
       "      <td>-0.456465</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.659690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.223721</td>\n",
       "      <td>-0.476284</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.659690</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.611972</td>\n",
       "      <td>-0.406194</td>\n",
       "      <td>3</td>\n",
       "      <td>1.050278</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Age      Fare  Pclass  FamilySize  Cabin_B  Cabin_C  Cabin_D  Cabin_E  \\\n",
       "0  0.358655 -0.492396       3   -0.659690        0        1        0        0   \n",
       "1  1.329283 -0.508429       3    0.195294        0        1        0        0   \n",
       "2  2.494035 -0.456465       2   -0.659690        0        1        0        0   \n",
       "3 -0.223721 -0.476284       3   -0.659690        0        1        0        0   \n",
       "4 -0.611972 -0.406194       3    1.050278        0        1        0        0   \n",
       "\n",
       "   Cabin_F  Cabin_G     ...       Ticket_C  Ticket_F  Ticket_L  Ticket_P  \\\n",
       "0        0        0     ...              0         0         0         0   \n",
       "1        0        0     ...              0         0         0         0   \n",
       "2        0        0     ...              0         0         0         0   \n",
       "3        0        0     ...              0         0         0         0   \n",
       "4        0        0     ...              0         0         0         0   \n",
       "\n",
       "   Ticket_S  Ticket_W  Title_Miss  Title_Mr  Title_Mrs  Title_Other  \n",
       "0         0         0           0         1          0            0  \n",
       "1         0         0           0         0          1            0  \n",
       "2         0         0           0         1          0            0  \n",
       "3         0         0           0         1          0            0  \n",
       "4         0         0           0         0          1            0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:13:14.531460Z",
     "start_time": "2018-06-28T04:13:14.395481Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, VotingClassifier, ExtraTreesClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:13:15.041191Z",
     "start_time": "2018-06-28T04:13:15.037237Z"
    }
   },
   "outputs": [],
   "source": [
    "def tune_score_model(model, param_grid, X, y, n_jobs=-1, cv=3):\n",
    "    \n",
    "    #Runs a GridSearchCV for the model and param_grid passed into the function\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring='roc_auc', n_jobs=n_jobs, verbose=1, cv=cv)\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    #Returns the best score and params used to get the score\n",
    "    return grid.best_score_, grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:28:00.488602Z",
     "start_time": "2018-06-28T04:13:37.265619Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.7min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  3.0min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extra Trees\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   46.0s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:  3.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Fitting 3 folds for each of 576 candidates, totalling 1728 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:   50.9s\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed:  2.3min\n",
      "[Parallel(n_jobs=-1)]: Done 1728 out of 1728 | elapsed:  3.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "Fitting 3 folds for each of 288 candidates, totalling 864 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 864 out of 864 | elapsed:  2.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost\n",
      "Fitting 3 folds for each of 245 candidates, totalling 735 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done 735 out of 735 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "#List of Model Names and a True / False value that specifies whether to run the model or not\n",
    "models = [\n",
    "          ['AdaBoost', True],\n",
    "          ['Extra Trees', True],\n",
    "          ['Random Forest', True], \n",
    "          ['Voting Classifier', True],\n",
    "          ['XGBoost', True] \n",
    "         ]\n",
    "\n",
    "#Models to run along with any variables that we want to specify\n",
    "model_obj = [\n",
    "          AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), learning_rate=0.1, n_estimators=500, random_state=29),\n",
    "    \n",
    "          ExtraTreesClassifier(random_state=29),\n",
    "    \n",
    "          RandomForestClassifier(random_state=29), \n",
    "    \n",
    "          VotingClassifier(estimators=[('lr', LogisticRegression(random_state=29)),\n",
    "                            ('nb', GaussianNB()),\n",
    "                            ('knn', KNeighborsClassifier()),\n",
    "                            ('rf', RandomForestClassifier(random_state=29, n_estimators=500))],\n",
    "                           voting='soft'\n",
    "                          ),\n",
    "    \n",
    "          XGBClassifier(learning_rate=0.1, n_estimators=500, objective='binary:logistic', \n",
    "                        nthread=4, scale_pos_weight=1, seed=29,\n",
    "                        subsample=0.8, colsample_bytree=0.8, reg_alpha=0.1) #These three probably need to be tuned further\n",
    "          \n",
    "         ]\n",
    "\n",
    "#The param_grid values for each of the models\n",
    "param_grids = [\n",
    "               #AdaBoost\n",
    "               {\"base_estimator__criterion\": [\"gini\", \"entropy\"],\n",
    "                \"base_estimator__min_samples_split\": [2, 10, 20],\n",
    "                \"base_estimator__max_depth\": [1, 2, 5, 10],\n",
    "                \"base_estimator__min_samples_leaf\": [1, 5, 10],\n",
    "                \"base_estimator__max_leaf_nodes\": [None, 5, 10, 20]},\n",
    "               #Extra Trees\n",
    "               {\"n_estimators\": [200, 500],\n",
    "                \"max_depth\": [3, None],\n",
    "                \"max_features\": [1, 3, 5, 10],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 3, 10],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": ['gini', 'entropy']},\n",
    "               #Random Forest\n",
    "               {\"n_estimators\": [200, 500],\n",
    "                \"max_depth\": [3, None],\n",
    "                \"max_features\": [1, 3, 5, 10],\n",
    "                \"min_samples_split\": [2, 5, 10],\n",
    "                \"min_samples_leaf\": [1, 3, 10],\n",
    "                \"bootstrap\": [True, False],\n",
    "                \"criterion\": ['gini', 'entropy']},\n",
    "               #VotingClassifier\n",
    "               {\"lr__penalty\": ['l1', 'l2'],\n",
    "                \"lr__C\": [1, 10, 100],\n",
    "                \"rf__max_depth\": [3, 5, None],\n",
    "                \"rf__criterion\": ['gini', 'entropy'],\n",
    "                \"knn__n_neighbors\": [3,5,7,9],\n",
    "                \"knn__weights\": ['uniform', 'distance']\n",
    "               },\n",
    "               #XGBoost\n",
    "               {'max_depth':range(3,10,1),\n",
    "                'min_child_weight':range(1,6,1), \n",
    "                'gamma':[i/10.0 for i in range(0,7)]}\n",
    "              ]\n",
    "\n",
    "#Initialize as empty lists\n",
    "best_scores = []\n",
    "best_params = []\n",
    "\n",
    "#Look through all the models and run the tune_score_model function (if set to True). \n",
    "#The results of the function are saved to the best_scores and best_params lists\n",
    "n_out = 0\n",
    "for i in range(len(model_obj)):  \n",
    "    if models[i][1]:\n",
    "        best_scores.append(n_out)\n",
    "        best_params.append(n_out)\n",
    "        print(models[i][0])\n",
    "        best_scores[n_out], best_params[n_out] = tune_score_model(model_obj[i], param_grids[i], X_train, y_train, n_jobs=-1)\n",
    "        n_out = n_out + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:28:40.615459Z",
     "start_time": "2018-06-28T04:28:40.592301Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>best_scores</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.879286</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Extra Trees</td>\n",
       "      <td>0.879102</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'gini', 'max...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.877313</td>\n",
       "      <td>{'gamma': 0.5, 'max_depth': 4, 'min_child_weig...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Voting Classifier</td>\n",
       "      <td>0.876658</td>\n",
       "      <td>{'knn__n_neighbors': 5, 'knn__weights': 'unifo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.867414</td>\n",
       "      <td>{'base_estimator__criterion': 'entropy', 'base...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              models  best_scores  \\\n",
       "2      Random Forest     0.879286   \n",
       "1        Extra Trees     0.879102   \n",
       "4            XGBoost     0.877313   \n",
       "3  Voting Classifier     0.876658   \n",
       "0           AdaBoost     0.867414   \n",
       "\n",
       "                                         best_params  \n",
       "2  {'bootstrap': False, 'criterion': 'gini', 'max...  \n",
       "1  {'bootstrap': False, 'criterion': 'gini', 'max...  \n",
       "4  {'gamma': 0.5, 'max_depth': 4, 'min_child_weig...  \n",
       "3  {'knn__n_neighbors': 5, 'knn__weights': 'unifo...  \n",
       "0  {'base_estimator__criterion': 'entropy', 'base...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output = pd.DataFrame(\n",
    "    {'models': [val for val, is_true in models if is_true], \n",
    "     'best_scores': best_scores, 'best_params': best_params}, \n",
    "    columns=['models', 'best_scores', 'best_params']).sort_values(by='best_scores', ascending=False)\n",
    "model_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:29:41.965828Z",
     "start_time": "2018-06-28T04:29:41.961685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.5, 'max_depth': 4, 'min_child_weight': 5}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:29:48.477790Z",
     "start_time": "2018-06-28T04:29:42.368402Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0.6, learning_rate=0.01,\n",
       "       max_delta_step=0, max_depth=8, min_child_weight=5, missing=None,\n",
       "       n_estimators=5000, n_jobs=1, nthread=4, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=1e-05, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=29, silent=True, subsample=0.8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = XGBClassifier(learning_rate =0.01, \n",
    "                      n_estimators=5000, \n",
    "                      max_depth=8,\n",
    "                      min_child_weight=5, \n",
    "                      gamma=0.6, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      reg_alpha=1e-05,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:31:06.340104Z",
     "start_time": "2018-06-28T04:31:05.978616Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "feature_import = pd.DataFrame.from_dict(classifier.get_booster().get_fscore(), orient='index')\n",
    "feature_import.columns = ['values']\n",
    "feature_import.sort_values(['values'], ascending=False, inplace=True)\n",
    "feature_import.reset_index(level=0, inplace=True)\n",
    "sns.barplot(x='index', y='values', data=feature_import, palette='deep')\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:31:25.697072Z",
     "start_time": "2018-06-28T04:31:25.651493Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/patornute/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-28T04:31:26.302539Z",
     "start_time": "2018-06-28T04:31:26.287705Z"
    }
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(y_pred, columns=['Survived']).astype(int)\n",
    "output['PassengerId'] = df_total[df_total['Train'] == 0]['PassengerId']\n",
    "output.to_csv('XGBoost.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extra: Tuning XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T09:17:01.379461Z",
     "start_time": "2018-06-26T09:16:36.011755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] n_estimators=100 ................................................\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] n_estimators=200 ................................................\n",
      "[CV] n_estimators=300 ................................................\n",
      "[CV] n_estimators=300 ................................................\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e7069122d957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mgrid0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Next, we will tune the n_estimators\n",
    "\n",
    "param_grid0 = {'n_estimators': [100, 200, 300, 400, 500]}\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      max_depth=5,\n",
    "                      min_child_weight=1, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "grid0 = GridSearchCV(estimator=model, param_grid=param_grid0, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "grid0.fit(X_train, y_train)\n",
    "\n",
    "print(grid0.best_score_)\n",
    "print(grid0.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-26T09:16:01.296795Z",
     "start_time": "2018-06-26T09:14:11.814445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 35 candidates, totalling 105 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c698597f54c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mgrid1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparam_grid1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mgrid1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/envs/latest/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    697\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.5/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Next, we will tune the max_depth and min_child_weight\n",
    "\n",
    "param_grid1 = {'max_depth':range(3,10,1),\n",
    "               'min_child_weight':range(1,6,1)}\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=5,\n",
    "                      min_child_weight=1, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "grid1 = GridSearchCV(estimator=model, param_grid=param_grid1, scoring='roc_auc', n_jobs=-1, verbose=2)\n",
    "grid1.fit(X_train, y_train)\n",
    "\n",
    "print(grid1.best_score_)\n",
    "print(grid1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-26T09:13:26.422Z"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we will tune gamma using the values for max_depth (4) and min_child_weight (5) that we found\n",
    "\n",
    "param_grid2 = {'gamma':[i/10.0 for i in range(0,7)]}\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=4,\n",
    "                      min_child_weight=5, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "grid2 = GridSearchCV(estimator=model, param_grid=param_grid2, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid2.fit(X_train, y_train)\n",
    "\n",
    "print(grid2.best_score_)\n",
    "print(grid2.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-26T09:13:26.424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Next, we will tune subsample and colsample_bytree using the gamma value we found (0.0) as well as the values for max_depth and min_child_weight\n",
    "\n",
    "param_grid3 = {'subsample':[i/100.0 for i in range(60,100,5)],\n",
    "               'colsample_bytree':[i/100.0 for i in range(60,100,5)]}\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=4,\n",
    "                      min_child_weight=5, \n",
    "                      gamma=0.0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.8,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "grid3 = GridSearchCV(estimator=model, param_grid=param_grid3, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid3.fit(X_train, y_train)\n",
    "\n",
    "print(grid3.best_score_)\n",
    "print(grid3.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-06-26T09:13:26.426Z"
    }
   },
   "outputs": [],
   "source": [
    "# Finally, we will tune reg_alpha\n",
    "\n",
    "param_grid4 = {'reg_alpha':[1e-5, 1e-2, 0.1, 1, 100]}\n",
    "\n",
    "model = XGBClassifier(learning_rate =0.1, \n",
    "                      n_estimators=100, \n",
    "                      max_depth=4,\n",
    "                      min_child_weight=5, \n",
    "                      gamma=0, \n",
    "                      subsample=0.8, \n",
    "                      colsample_bytree=0.95,\n",
    "                      objective= 'binary:logistic', \n",
    "                      nthread=4, \n",
    "                      scale_pos_weight=1, \n",
    "                      seed=29)\n",
    "\n",
    "grid4 = GridSearchCV(estimator=model, param_grid=param_grid4, scoring='roc_auc', n_jobs=-1, verbose=1)\n",
    "grid4.fit(X_train, y_train)\n",
    "\n",
    "print(grid4.best_score_)\n",
    "print(grid4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
